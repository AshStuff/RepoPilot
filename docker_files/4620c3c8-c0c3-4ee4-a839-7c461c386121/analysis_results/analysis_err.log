container_agent.py: Execution started.
container_agent.py: Initial imports (json, logging) successful.
container_agent.py: Attempting to import create_agent from cursor_agent_tools.
container_agent.py: Successfully imported create_agent.
container_agent.py: Script __main__ started.
container_agent.py: main() started.
2025-05-25 10:52:54,163 - INFO - Container agent started (logged to stderr via logger config).
container_agent.py: Checking for issue file at /app/issue.txt
2025-05-25 10:52:54,163 - INFO - Successfully read issue content from /app/issue.txt
container_agent.py: Successfully read /app/issue.txt
container_agent.py: _get_repo_path called
container_agent.py: Using REPO_BASENAME env var, repo path: /workspace/JunkRepo
2025-05-25 10:52:54,163 - INFO - Repository path determined as: /workspace/JunkRepo
container_agent.py: Repository path: /workspace/JunkRepo
2025-05-25 10:52:54,164 - INFO - Found 25 files in codebase at /workspace/JunkRepo (excluding .git and hidden files)
container_agent.py: Initializing LLM agent...
2025-05-25 10:52:54,164 - cursor_agent_tools.factory - [32mINFO[0m - Creating agent with model: ollama-qwen2.5-coder
2025-05-25 10:52:54,164 - [32mINFO[0m - Creating agent with model: ollama-qwen2.5-coder
2025-05-25 10:52:54,164 - cursor_agent_tools.factory - [32mINFO[0m - Creating OllamaAgent with model ollama-qwen2.5-coder
2025-05-25 10:52:54,164 - [32mINFO[0m - Creating OllamaAgent with model ollama-qwen2.5-coder
2025-05-25 10:52:54,165 - cursor_agent_tools.ollama_agent - [32mINFO[0m - Initializing Ollama agent with model ollama-qwen2.5-coder
2025-05-25 10:52:54,165 - [32mINFO[0m - Initializing Ollama agent with model ollama-qwen2.5-coder
2025-05-25 10:52:54,170 - INFO - HTTP Request: GET http://host.docker.internal:11434/api/tags "HTTP/1.1 200 OK"
2025-05-25 10:52:54,170 - cursor_agent_tools.ollama_agent - [33mWARNING[0m - No models found in Ollama server. Please pull a model first.
2025-05-25 10:52:54,170 - [33mWARNING[0m - No models found in Ollama server. Please pull a model first.
2025-05-25 10:52:54,170 - cursor_agent_tools.ollama_agent - [33mWARNING[0m - Model 'qwen2.5-coder' not found in available models. You may need to pull it with 'ollama pull qwen2.5-coder'. Available models: None
2025-05-25 10:52:54,170 - [33mWARNING[0m - Model 'qwen2.5-coder' not found in available models. You may need to pull it with 'ollama pull qwen2.5-coder'. Available models: None
2025-05-25 10:52:54,170 - INFO - LLM agent initialized.
container_agent.py: LLM agent initialized.
2025-05-25 10:52:54,170 - INFO - Agent tools registered.
container_agent.py: Agent tools registered.
2025-05-25 10:52:54,171 - INFO - Prompting LLM agent. Issue content length: 114, Codebase files: 25
2025-05-25 10:52:54,177 - INFO - HTTP Request: POST http://host.docker.internal:11434/api/chat "HTTP/1.1 404 Not Found"
2025-05-25 10:52:54,178 - cursor_agent_tools.ollama_agent - [31mERROR[0m - Error in Ollama chat: model "qwen2.5-coder" not found, try pulling it first (status code: 404)
2025-05-25 10:52:54,178 - [31mERROR[0m - Error in Ollama chat: model "qwen2.5-coder" not found, try pulling it first (status code: 404)
2025-05-25 10:52:54,178 - INFO - LLM agent chat completed.
2025-05-25 10:52:54,178 - ERROR - Error processing LLM JSON response: _log() got an unexpected keyword argument 'file'
2025-05-25 10:52:54,178 - INFO - Analysis output successfully written to /workspace/analysis_results/analysis_output.json
container_agent.py: LLM agent chat completed.
container_agent.py: Output written to /workspace/analysis_results/analysis_output.json
Analysis complete. Output written to /workspace/analysis_results/analysis_output.json
container_agent.py: main() finished.
