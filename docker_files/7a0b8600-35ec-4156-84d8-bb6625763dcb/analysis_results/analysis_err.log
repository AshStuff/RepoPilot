container_agent.py: Execution started.
container_agent.py: Initial imports (json, logging) successful.
container_agent.py: Attempting to import create_agent from cursor_agent_tools.
container_agent.py: Successfully imported create_agent.
container_agent.py: Script __main__ started.
container_agent.py: main() started.
2025-05-25 10:56:58,421 - INFO - Container agent started (logged to stderr via logger config).
container_agent.py: Checking for issue file at /app/issue.txt
2025-05-25 10:56:58,421 - INFO - Successfully read issue content from /app/issue.txt
container_agent.py: Successfully read /app/issue.txt
container_agent.py: _get_repo_path called
container_agent.py: Using REPO_BASENAME env var, repo path: /workspace/JunkRepo
2025-05-25 10:56:58,421 - INFO - Repository path determined as: /workspace/JunkRepo
container_agent.py: Repository path: /workspace/JunkRepo
2025-05-25 10:56:58,422 - INFO - Found 25 files in codebase at /workspace/JunkRepo (excluding .git and hidden files)
container_agent.py: Initializing LLM agent...
2025-05-25 10:56:58,422 - cursor_agent_tools.factory - [32mINFO[0m - Creating agent with model: ollama-qwen2.5-coder
2025-05-25 10:56:58,422 - [32mINFO[0m - Creating agent with model: ollama-qwen2.5-coder
2025-05-25 10:56:58,422 - cursor_agent_tools.factory - [32mINFO[0m - Creating OllamaAgent with model ollama-qwen2.5-coder
2025-05-25 10:56:58,422 - [32mINFO[0m - Creating OllamaAgent with model ollama-qwen2.5-coder
2025-05-25 10:56:58,422 - cursor_agent_tools.ollama_agent - [32mINFO[0m - Initializing Ollama agent with model ollama-qwen2.5-coder
2025-05-25 10:56:58,422 - [32mINFO[0m - Initializing Ollama agent with model ollama-qwen2.5-coder
2025-05-25 10:56:58,428 - INFO - HTTP Request: GET http://host.docker.internal:11434/api/tags "HTTP/1.1 200 OK"
2025-05-25 10:56:58,428 - cursor_agent_tools.ollama_agent - [33mWARNING[0m - No models found in Ollama server. Please pull a model first.
2025-05-25 10:56:58,428 - [33mWARNING[0m - No models found in Ollama server. Please pull a model first.
2025-05-25 10:56:58,428 - cursor_agent_tools.ollama_agent - [33mWARNING[0m - Model 'qwen2.5-coder' not found in available models. You may need to pull it with 'ollama pull qwen2.5-coder'. Available models: None
2025-05-25 10:56:58,428 - [33mWARNING[0m - Model 'qwen2.5-coder' not found in available models. You may need to pull it with 'ollama pull qwen2.5-coder'. Available models: None
2025-05-25 10:56:58,428 - INFO - LLM agent initialized.
container_agent.py: LLM agent initialized.
2025-05-25 10:56:58,428 - INFO - Agent tools registered.
container_agent.py: Agent tools registered.
2025-05-25 10:56:58,428 - INFO - Prompting LLM agent. Issue content length: 114, Codebase files: 25
2025-05-25 10:57:01,620 - INFO - HTTP Request: POST http://host.docker.internal:11434/api/chat "HTTP/1.1 200 OK"
2025-05-25 10:57:01,620 - INFO - LLM agent chat completed.
2025-05-25 10:57:01,621 - ERROR - Error processing LLM JSON response: _log() got an unexpected keyword argument 'file'
2025-05-25 10:57:01,621 - INFO - Analysis output successfully written to /workspace/analysis_results/analysis_output.json
container_agent.py: LLM agent chat completed.
container_agent.py: Output written to /workspace/analysis_results/analysis_output.json
Analysis complete. Output written to /workspace/analysis_results/analysis_output.json
container_agent.py: main() finished.
